{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from segment2d import *\n",
    "import nibabel as nib\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import kornia as K\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "import SimpleITK as sitk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair_full = np.zeros((len(list_file_flair), 240, 240, 155))\n",
    "# t1_full = np.zeros((len(list_file_flair), 240, 240, 155))\n",
    "# t2_full = np.zeros((len(list_file_flair), 240, 240, 155))\n",
    "# for count_subject, path_flair in tqdm(enumerate(list_file_flair)):\n",
    "\n",
    "#     flair = nib.load(path_flair).get_fdata()\n",
    "#     t1 = nib.load(path_flair.replace(\"flair\", \"t1\")).get_fdata()\n",
    "#     t2 = nib.load(path_flair.replace(\"flair\", \"t2\")).get_fdata()\n",
    "#     # caculate mean std for all data\n",
    "    \n",
    "#     flair = min_max_normalize(flair)\n",
    "#     t1 = min_max_normalize(t1)\n",
    "#     t2 = min_max_normalize(t2)\n",
    "    \n",
    "#     flair_full[count_subject] = flair\n",
    "#     t1_full[count_subject] = t1\n",
    "#     t2_full[count_subject] = t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_flair, std_flair = np.mean(flair_full[flair_full != 0]), np.std(flair_full[flair_full != 0])\n",
    "# mean_t1, std_t1 = np.mean(t1_full[t1_full != 0]), np.std(t1_full[t1_full != 0])\n",
    "# mean_t2, std_t2 = np.mean(t2_full[t2_full != 0]), np.std(t2_full[t2_full != 0])\n",
    "# dict_mean_std = {}\n",
    "# dict_mean_std[\"mean_flair\"] = mean_flair.tolist()\n",
    "# dict_mean_std[\"mean_t2\"] = mean_t2.tolist()\n",
    "# dict_mean_std[\"mean_t1\"] = mean_t1.tolist()\n",
    "# dict_mean_std[\"std_flair\"] = mean_t2.tolist()\n",
    "# dict_mean_std[\"std_t2\"] = std_t2.tolist()\n",
    "# dict_mean_std[\"std_t1\"] = std_t1.tolist()\n",
    "# with open('mean_std_brats_norm.yaml', 'w') as outfile:\n",
    "#     # Write the dictionary to the file\n",
    "#     yaml.dump(dict_mean_std, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_flair = glob.glob(\"data/msseg-2008-training-nii/*/*FLAIR_brain.nii.gz\")\n",
    "for flair_dir in list_of_flair:\n",
    "    flair = nib.load(flair_dir).get_fdata()\n",
    "    mask = nib.load(flair_dir.replace(\"FLAIR_brain\", \"lesion\")).get_fdata()\n",
    "    # padded_flair, crop_index, padded_index = pad_background(flair, dim2pad=(320,320,320))\n",
    "\n",
    "    # padded_mask = pad_background_with_index(mask, crop_index, padded_index, dim2pad=(320,320,320))\n",
    "    padded_flair = flair[96:416,96:416,96:416]\n",
    "    padded_mask = mask[96:416,96:416,96:416]\n",
    "    if np.sum(padded_mask)-np.sum(mask) != 0:\n",
    "        print(np.sum(padded_mask)-np.sum(mask))\n",
    "        print(flair_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_dir = glob.glob(\"data/msseg-2008-training-nii/*/*FLAIR_brain.nii.gz\")[-1]\n",
    "\n",
    "flair = nib.load(flair_dir).get_fdata()\n",
    "mask = nib.load(flair_dir.replace(\"FLAIR_brain\", \"lesion\")).get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the center indice with shape 320,320,320 from shape 512,512,512\n",
    "padded_flair = flair[96:416,96:416,96:416]\n",
    "padded_mask = mask[96:416,96:416,96:416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef4717e88bf41e28cfb635be1ca41ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='index', max=500), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_segmentation(index)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flair = nib.load(\"data/data_isbi_2015/training/training01/preprocessed/training01_01_flair_pp.nii\").get_fdata()\n",
    "# aug_flair = augmentation(image=image_flair)[\"image\"]\n",
    "def show_segmentation(index):\n",
    "    try:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.subplot(1, 5, 1),\n",
    "        plt.imshow(padded_flair[index]),\n",
    "        plt.subplot(1, 5, 2),\n",
    "        plt.imshow(flair[index]),\n",
    "        plt.subplot(1, 5, 3),\n",
    "        plt.imshow(mask[index]),\n",
    "        plt.subplot(1, 5, 4),\n",
    "        plt.imshow(padded_mask[index]),\n",
    "        plt.show(),\n",
    "    except:\n",
    "        pass\n",
    "    # plt.subplot(1, 5, 5),\n",
    "    # plt.imshow(augmented_mask),\n",
    "interact(show_segmentation, index=(0,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import ants\n",
    "import ants.utils.bias_correction as ants_bias\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# this file is used to convert the msseg2008 dataset to nifti format\n",
    "# then remove brain skull based on t1 weighted then filter to T2 and FLAIR\n",
    "# correct bias field\n",
    "# sub_data = \"training\" or \"testing\"\n",
    "# the final dataset is stored in data/msseg-2008-{sub_data}-nii\n",
    "# the original dataset is stored in data/msseg-2008-{sub_data}\n",
    "# it requires fsl and antspyx to be installed\n",
    "\n",
    "FSLDIR = os.environ.get('FSLDIR')\n",
    "\n",
    "datasets = [\"training\", \"testing\"]\n",
    "\n",
    "for sub_data in datasets:\n",
    "    PATH = f'data/msseg-2008-{sub_data}/'\n",
    "    dir_list = []\n",
    "    file_list = []\n",
    "    for folder in os.listdir(PATH):\n",
    "        dir_list.append(folder)\n",
    "    for folder in dir_list:\n",
    "        folder_path = os.path.join(PATH, folder)\n",
    "        for image in os.listdir(folder_path):\n",
    "            if image.endswith(\".nhdr\"):\n",
    "                file_list.append((folder, image[:-5]))\n",
    "    \n",
    "    print(f\"remove brain skull and save to folder {sub_data} with _brain.nii.gz ...\")\n",
    "\n",
    "    for image in tqdm(file_list):\n",
    "        (folder, file) = image\n",
    "        img = sitk.ReadImage(f'{PATH}/{folder}/{file}.nhdr')\n",
    "        newfile = file + \".nii.gz\"\n",
    "        NEW_PATH = f'data/msseg-2008-{sub_data}-nii/{folder}'\n",
    "        if not os.path.exists(NEW_PATH):\n",
    "            os.makedirs(NEW_PATH) \n",
    "        sitk.WriteImage(img, f'data/msseg-2008-{sub_data}-nii/{folder}/{newfile}')\n",
    "        if \"T1\" in file:\n",
    "            command = [f\"{FSLDIR}/bin/bet\", f'data/msseg-2008-{sub_data}-nii/{folder}/{file}', f'data/msseg-2008-{sub_data}-nii/{folder}/{file}_brain', \"-f\",\"0.5\",\"-g\",\"0\"]\n",
    "            subprocess.run(command, check = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.TRAIN.FOLD =5\n",
    "list_file_flair = sorted(glob.glob(f\"data/MSSEG-Training_2016/Training/Center*/*/Preprocessed_Data/*FLAIR*\"))\n",
    "list_file_flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair = nib.load(list_file_flair[0]).get_fdata()\n",
    "mask = nib.load(list_file_flair[0].replace(\"Preprocessed_Data\", \"Masks\").replace(\"FLAIR_preprocessed\",\"Consensus\")).get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file_flair = sorted(glob.glob(f\"data/msseg-2008-training/*\"))\n",
    "len(list_file_flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x7f4d0c4b8790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Nifti1Image' object has no attribute 'pixeltype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4481/793824755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNC_train_Case01_T1.nii.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn4_bias_field_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ants/utils/bias_correction.py\u001b[0m in \u001b[0;36mn4_bias_field_correction\u001b[0;34m(image, mask, rescale_intensities, shrink_factor, convergence, spline_param, return_bias_field, verbose, weight_mask)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mimage_n4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn4_bias_field_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixeltype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvergence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Nifti1Image' object has no attribute 'pixeltype'"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "a = nib.load(\"UNC_train_Case01_T1.nii.gz\")\n",
    "ants.n4_bias_field_correction(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANTsImage (RAI)\n",
       "\t Pixel Type : float (float32)\n",
       "\t Components : 1\n",
       "\t Dimensions : (512, 512, 512)\n",
       "\t Spacing    : (0.5, 0.5, 0.5)\n",
       "\t Origin     : (0.0, 0.0, 0.0)\n",
       "\t Direction  : [1. 0. 0. 0. 1. 0. 0. 0. 1.]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_flair = list_file_flair[10]\n",
    "flair = nib.load(path_flair).get_fdata()\n",
    "t1 = nib.load(path_flair.replace(\"FLAIR\", \"T1\")).get_fdata()\n",
    "t2 = nib.load(path_flair.replace(\"FLAIR\", \"T2\")).get_fdata()\n",
    "\n",
    "consensus = nib.load(path_flair.replace(\"Preprocessed_Data\", \"Masks\").replace(\"FLAIR_preprocessed\", \"Consensus\"))\n",
    "consensus = consensus.get_fdata().astype(np.uint8)\n",
    "\n",
    "padded_flair, crop_index, padded_index = pad_background(flair, dim2pad=cfg.DATA.DIM2PAD_MICCAI)\n",
    "padded_t1 = pad_background_with_index(t1, crop_index, padded_index)\n",
    "padded_t2 = pad_background_with_index(t2, crop_index, padded_index)\n",
    "padded_mask = pad_background_with_index(consensus, crop_index, padded_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_file_flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file_flair = sorted(glob.glob(f\"data/MSSEG-Training_2016/Training/Center*/*/Preprocessed_Data/*FLAIR*\"))\n",
    "list_file_flair = sorted(glob.glob(f\"data/MSSEG-Testing/Center*/*/Preprocessed_Data/*FLAIR*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_file_flair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_file_flair)):\n",
    "    flair = nib.load(list_file_flair[i]).get_fdata()\n",
    "    mask = nib.load(list_file_flair[i].replace(\"Preprocessed_Data\", \"Masks\").replace(\"FLAIR_preprocessed\",\"Consensus\")).get_fdata()\n",
    "    # padded_image, [padded_mask], crop_index = pad_background(flair, [mask])\n",
    "    if np.sum(mask) == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = flair\n",
    "padded_image, crop_index, padded_index = pad_background(image)\n",
    "padded_image, [padded_mask], crop_index = pad_background(image, [mask])\n",
    "\n",
    "# perform some operations on the padded image\n",
    "orig_image = invert_padding(image, padded_image, crop_index, padded_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(padded_mask)-np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(mask[crop_index]-padded_mask[crop_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(flair[crop_index]-orig_image[crop_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert = np.zeros_like(original_flair)\n",
    "# invert[crop_index] = padded_image[padded_index]\n",
    "np.linalg.norm(orig_image-original_flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89444e7967f4bde972769d130f29c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='index', max=500), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_segmentation(index)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flair = nib.load(\"data/data_isbi_2015/training/training01/preprocessed/training01_01_flair_pp.nii\").get_fdata()\n",
    "# aug_flair = augmentation(image=image_flair)[\"image\"]\n",
    "def show_segmentation(index):\n",
    "    try:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.subplot(1, 5, 1),\n",
    "        plt.imshow(padded_flair[...,index]),\n",
    "        plt.subplot(1, 5, 2),\n",
    "        plt.imshow(flair[...,index]),\n",
    "        # plt.subplot(1, 5, 3),\n",
    "        # plt.imshow(padded_t2[...,index]),\n",
    "        # plt.subplot(1, 5, 4),\n",
    "        # plt.imshow(padded_mask[...,index]),\n",
    "        plt.show(),\n",
    "    except:\n",
    "        pass\n",
    "    # plt.subplot(1, 5, 5),\n",
    "    # plt.imshow(augmented_mask),\n",
    "interact(show_segmentation, index=(0,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair = np.load(\"data/msseg2016npz/mri1_axial_50_mask1.npz\")[\"flair\"]\n",
    "mask = np.load(\"data/msseg2016npz/mri1_axial_50_mask1.npz\")[\"mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.from_numpy(flair.transpose(-1, 0, 1))[None]\n",
    "mask = torch.from_numpy(mask[None].astype(np.float32))[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(imgs_aug_image-flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform basic data augmentation using Kornia.\n",
    "from kornia.filters import GaussianBlur2d\n",
    "aug = K.augmentation.AugmentationSequential(\n",
    "    GaussianBlur2d((3, 3), (1.5, 1.5)),\n",
    "    # K.augmentation.ColorJitter((0.9, 1.1), (0.9, 1.1) , p=1),\n",
    "    # K.augmentation.RandomVerticalFlip(p=1),\n",
    "    # K.augmentation.RandomAffine(degrees=10, translate=0.0625, scale=(0.95, 1.05), p=1.0,),\n",
    "    # K.augmentation.RandomBrightness((1, 1.), p=1),\n",
    "    # data_keys=[\"input\", \"mask\"]\n",
    ")\n",
    "imgs_aug, mask_aug = aug(image), mask\n",
    "imgs_aug_image = K.tensor_to_image(imgs_aug)\n",
    "mask_aug_image = K.tensor_to_image(mask_aug)\n",
    "\n",
    "def show_segmentation(index):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, 5, 1),\n",
    "    plt.imshow(flair[..., index]),\n",
    "    plt.subplot(1, 5, 2),\n",
    "    plt.imshow(mask[0,0]),\n",
    "    plt.subplot(1, 5, 3),\n",
    "    plt.imshow(imgs_aug_image[..., index]),\n",
    "    plt.subplot(1, 5, 4),\n",
    "    plt.imshow(mask_aug_image),\n",
    "    # plt.subplot(1, 5, 5),\n",
    "    # plt.imshow(augmented_mask),\n",
    "    plt.show(),\n",
    "interact(show_segmentation, index=(0, flair.shape[-1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "img = sitk.ReadImage('data/msseg-2008-training/UNC_train_Case02/UNC_train_Case02_FLAIR.nhdr')\n",
    "sitk.WriteImage(img, 'UNC_train_Case01_FLAIR.nii.gz')\n",
    "\n",
    "img = sitk.ReadImage('data/msseg-2008-training/UNC_train_Case02/UNC_train_Case02_T1.nhdr')\n",
    "sitk.WriteImage(img, 'UNC_train_Case01_T1.nii.gz')\n",
    "\n",
    "img = sitk.ReadImage('data/msseg-2008-training/UNC_train_Case02/UNC_train_Case02_T2.nhdr')\n",
    "sitk.WriteImage(img, 'UNC_train_Case01_T2.nii.gz')\n",
    "\n",
    "img = sitk.ReadImage('data/msseg-2008-training/UNC_train_Case02/UNC_train_Case02_lesion_byCHB.nhdr')\n",
    "sitk.WriteImage(img, 'UNC_train_Case01_lesion_byCHB.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_train = sorted(glob.glob(\"data/msseg-2008-training/*/*lesion*nhdr\"))\n",
    "len(list_of_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel.processing as nib_pro\n",
    "t1 = nib.load(\"UNC_train_Case01_T1.nii.gz\")\n",
    "t1_2 = nib_pro.conform(t1, out_shape=(256, 256, 256), voxel_size=(1.0, 1.0, 1.0), orientation=\"LPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save t1_2 to nii.gz\n",
    "nib.save(t1_2, \"UNC_train_Case01_T1_2.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read numpy data from SimpleITK.SimpleITK.Image\n",
    "\n",
    "\n",
    "mask = sitk.GetArrayFromImage(sitk.ReadImage('data/msseg-2008-training/UNC_train_Case02/UNC_train_Case02_lesion_byCHB.nhdr'))\n",
    "t1 = sitk.GetArrayFromImage(sitk.ReadImage('data/msseg-2008-training/UNC_train_Case02/UNC_train_Case02_T1.nhdr'))\n",
    "# crop the center of the image t1 with size of 256 256 256\n",
    "for x in range(512):\n",
    "    if np.sum(mask) - np.sum(mask[x:x+256, x:x+256, x:x+256]) == 0:\n",
    "        print(x)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask) - np.sum(mask[x:x+256, x:x+256, x:x+256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_segmentation(index):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, 5, 1),\n",
    "    plt.imshow(padded_t1[:,:,index]),\n",
    "    plt.subplot(1, 5, 2),\n",
    "    plt.imshow(t1[:,:,index]),\n",
    "    # plt.subplot(1, 5, 3),\n",
    "    # plt.imshow(original_flair[:,index,:]),\n",
    "    # plt.subplot(1, 5, 4),\n",
    "    # plt.imshow(original_mask1[:,index,:]),\n",
    "    # plt.subplot(1, 5, 5),\n",
    "    # plt.imshow(augmented_mask),\n",
    "    plt.show(),\n",
    "interact(show_segmentation, index=(0, t1.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nib.load(\"predict_testset/test01_01_nhatvin.nii\").get_fdata()\n",
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_flair = nib.load(\"data/data_isbi_2015/training/training01/orig/training01_01_flair.nii.gz\").get_fdata()\n",
    "original_mask1 = nib.load(\"data/data_isbi_2015/training/training01/masks/training01_01_mask2.nii\").get_fdata()\n",
    "# original_flair, original_mask1 = pad_remove_background(original_flair, [original_mask1], dim2pad=cfg.DATA.DIM2PAD_ISBI)\n",
    "# original_mask1 = original_mask1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"data/data_isbi_2015/isbi2npz2D/mri1_axial_80_mask2.npz\")\n",
    "a[\"flair\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"flair\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject = np.load(\"data/data_isbi_2015/isbi2npz2D/mri1_axial_74_mask1.npz\")\n",
    "flair, mask = subject['flair'], subject['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(flair).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nz = np.nonzero(b)\n",
    "\n",
    "    # get the minimum and maximum indices along each axis\n",
    "    min_indices = np.min(nz, axis=1)\n",
    "    max_indices = np.max(nz, axis=1)\n",
    "\n",
    "    # crop the image to only include non-zero values\n",
    "    crop_index = tuple(slice(imin, imax+1) for imin, imax in zip(min_indices, max_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[crop_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_flair = nib.load(\"data/data_isbi_2015/training/training01/preprocessed/training01_01_flair_pp.nii\").get_fdata()\n",
    "original_mask1 = nib.load(\"data/data_isbi_2015/training/training01/masks/training01_01_mask2.nii\").get_fdata()\n",
    "def show_segmentation(index):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, 5, 1),\n",
    "    plt.imshow(original_flair[:,index,:]),\n",
    "    plt.subplot(1, 5, 2),\n",
    "    plt.imshow(original_mask1[:,index,:]),\n",
    "    # plt.subplot(1, 5, 3),\n",
    "    # plt.imshow(original_flair[:,index,:]),\n",
    "    # plt.subplot(1, 5, 4),\n",
    "    # plt.imshow(original_mask1[:,index,:]),\n",
    "    # plt.subplot(1, 5, 5),\n",
    "    # plt.imshow(augmented_mask),\n",
    "    plt.show(),\n",
    "interact(show_segmentation, index=(0, original_flair.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0, 100, size=(224, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x.transpose((1, 2, 0))\n",
    "x2 = np.expand_dims(x1, axis=-1)\n",
    "x2 = x2.transpose((2, 0, 1, -1))\n",
    "\n",
    "np.linalg.norm(x - x2[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"predict_testset/training05_01_view1.npy\")\n",
    "b = np.load(\"predict_testset/training05_01_view2.npy\")\n",
    "c = np.load(\"predict_testset/training05_01_view3.npy\")\n",
    "seg1 = a+b+c\n",
    "seg1 = np.argmax(seg1, axis=-1)\n",
    "a =  np.argmax(a, axis=-1)\n",
    "b =  np.argmax(b, axis=-1)\n",
    "c =  np.argmax(c, axis=-1)\n",
    "seg2 = a+b+c\n",
    "seg2 = (seg2>=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = nib.load(\"data/data_isbi_2015/training/training05/masks/training05_01_mask1.nii\").get_fdata()\n",
    "print(dice_MS_volume(a, mask2))\n",
    "print(dice_MS_volume(b, mask2))\n",
    "print(dice_MS_volume(c, mask2))\n",
    "print(dice_MS_volume(seg1, mask2))\n",
    "print(dice_MS_volume(seg2, mask2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = nib.load(\"data/data_isbi_2015/training/training05/masks/training05_03_mask1.nii\").get_fdata()\n",
    "print(dice_MS_volume(a, mask2))\n",
    "print(dice_MS_volume(b, mask2))\n",
    "print(dice_MS_volume(c, mask2))\n",
    "print(dice_MS_volume(seg1, mask2))\n",
    "print(dice_MS_volume(seg2, mask2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair = nib.load(list_file_flair[0]).get_fdata()\n",
    "flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on axial a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, valid_index = pad_remove_background(flair)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_file_flair[0:1])\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATA.ORIGIN2CUT = [(1, 2, 0), (0, 2, 1), (0, 1, 2)]\n",
    "cfg.DATA.CUT2ORIGIN = [(2, 0, 1), (0, 2, 1), (0, 1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagex = flair.transpose(cfg.DATA.ORIGIN2CUT[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = imagex[..., 50:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(mask1[..., 42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair = np.load(\"data/data_isbi_2015/isbi2npz2D/mri1_coronal_100_mask2.npz\")[\"flair\"]\n",
    "mask = np.load(\"data/data_isbi_2015/isbi2npz2D/mri1_coronal_100_mask2.npz\")[\"mask\"]\n",
    "def show_segmentation(index):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, 5, 1),\n",
    "    plt.imshow(flair[...,index]),\n",
    "    plt.subplot(1, 5, 2),\n",
    "    plt.imshow(mask),\n",
    "    # plt.subplot(1, 5, 3),\n",
    "    # plt.imshow(c[index]),\n",
    "    # plt.subplot(1, 5, 4),\n",
    "    # plt.imshow(mask2[index,:]),\n",
    "    # plt.subplot(1, 5, 5),\n",
    "    # plt.imshow(augmented_mask),\n",
    "    plt.show(),\n",
    "interact(show_segmentation, index=(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidIndex(volume, size=(160, 192, 155)):\n",
    "    \"\"\" this function remove unnescessary background and center crop remaining part \"\"\"\n",
    "    x_indexes, y_indexes, z_indexes = np.nonzero(np.sum(volume, axis=0) != 0)\n",
    "    dims_min = np.min([x_indexes, y_indexes, z_indexes], axis=1)\n",
    "    dims_max = np.max([x_indexes, y_indexes, z_indexes], axis=1)\n",
    "\n",
    "    dims_min = dims_min + (dims_max - dims_min - size) // 2\n",
    "    dims_min[dims_min < 0] = 0\n",
    "    dims_min[-1] = 0 # because size[-1] always is larger than true size, remove this line for another task.\n",
    "    dims_max = dims_min + size\n",
    "    return tuple(slice(imin, imax) for imin, imax in zip(dims_min, dims_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "a = np.ones((4, 2, 2, 2))\n",
    "b = np.ones((4, 2, 2, 2))\n",
    "c= np.ones((4, 2, 2, 2))\n",
    "d = np.ones((4, 2, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.append(a)\n",
    "e.append(b)\n",
    "e.append(c)\n",
    "e.append(d)\n",
    "e = np.mean(np.stack(e, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(e-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = nib.load(path_flair.replace(\"flair_pp\", \"mask1\").replace(\"preprocessed\", \"masks\")).get_fdata()\n",
    "mask2 = nib.load(path_flair.replace(\"flair_pp\", \"mask2\").replace(\"preprocessed\", \"masks\")).get_fdata()\n",
    "\n",
    "mask = np.logical_or(mask1, mask2).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.argmax(y_pred, axis=1).transpose(1, 2, 0)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[valid_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros_like(flair)\n",
    "seg[..., 1:-1] = output[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5ad64ac31307a54ea4f15d2b933f67c49aa406818b6ca8538d6cddd7352d117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
