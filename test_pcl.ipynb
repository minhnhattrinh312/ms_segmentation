{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PCL import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from segment2d import *\n",
    "import nibabel as nib\n",
    "from torchsummary import summary\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import csv\n",
    "import kornia as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.PREDICT.MODEL = \"resnet50\"\n",
    "cfg.TRAIN.LOSS = \"MSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    os.makedirs(f\"./weights_isbi_{cfg.PREDICT.MODEL}_{cfg.TRAIN.LOSS}/fold{i}/\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! load pretrained model !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! load pretrained model !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "no checkpoint found\n"
     ]
    }
   ],
   "source": [
    "from PCL import *\n",
    "from tqdm import tqdm\n",
    "from timm.optim import Nadam\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import ResNet50_Weights\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! load pretrained model !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "model1 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "model = ConvNextEncoder(in_dim = cfg.DATA.DIM_SIZE, num_class=cfg.DATA.NUM_CLASS)\n",
    "checkpoint = torch.hub.load_state_dict_from_url(url=convnext_urls[\"convnext_tiny_1k\"], map_location=\"cpu\", check_hash=True)\n",
    "model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! load pretrained model !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "model1 = ConvNextEncoder(in_dim = cfg.DATA.DIM_SIZE, num_class=cfg.DATA.NUM_CLASS)\n",
    "\n",
    "if cfg.TRAIN.LOAD_CKPT:\n",
    "    #load checkpoint\n",
    "    try:\n",
    "        checkpoint = torch.load(cfg.DIRS.SAVE_CONVNEXT + \"last.pt\")\n",
    "        model1.load_state_dict(checkpoint)\n",
    "        print(\"load last model\")\n",
    "    except:\n",
    "        print(\"no checkpoint found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = PCL_Resnet50(\n",
    "    model1,\n",
    "    image_size = 224,\n",
    "    hidden_layer_pixel = 'layer4',  # leads to output of 8x8 feature map for pixel-level learning\n",
    "    hidden_layer_instance = -2,     # leads to output for instance-level learning\n",
    "    projection_size = 256,          # size of projection output, 256 was used in the paper\n",
    "    projection_hidden_size = 2048,  # size of projection hidden dimension, paper used 2048\n",
    "    moving_average_decay = 0.99,    # exponential moving average decay of target encoder\n",
    "    ppm_num_layers = 1,             # number of layers for transform function in the pixel propagation module, 1 was optimal\n",
    "    ppm_gamma = 2,                  # sharpness of the similarity in the pixel propagation module, already at optimal value of 2\n",
    "    distance_thres = 0.7,           # ideal value is 0.7, as indicated in the paper, which makes the assumption of each feature map's pixel diagonal distance to be 1 (still unclear)\n",
    "    similarity_temperature = 0.3,   # temperature for the cosine similarity for the pixel contrastive loss\n",
    "    alpha = 1.,                     # weight of the pixel propagation loss (pixpro) vs pixel CL loss\n",
    "    use_pixpro = True,              # do pixel pro instead of pixel contrast loss, defaults to pixpro, since it is the best one\n",
    "    cutout_ratio_range = (0.6, 0.8) # a random ratio is selected from this range for the random cutout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipNet(in_dim = cfg.DATA.DIM_SIZE, num_class=cfg.DATA.NUM_CLASS)\n",
    "segmenter = Segmenter(model, cfg.DATA.CLASS_WEIGHT, cfg.DATA.NUM_CLASS, \n",
    "                                        cfg.OPT.LEARNING_RATE, cfg.OPT.FACTOR_LR, cfg.OPT.PATIENCE_LR)\n",
    "\n",
    "for layer in list(segmenter.model.children())[:2]:\n",
    "    for parameter in layer.parameters():\n",
    "        parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! load pretrained model !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet50\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,          \n",
    "    # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    "    activation = \"softmax2d\"\n",
    ")\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! load pretrained model !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "# model.encoder.load_state_dict(torch.load(cfg.DIRS.SAVE_RESNET50 + \"best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.load_state_dict(torch.load(cfg.DIRS.SAVE_RESNET50 + \"best_model.pt\"))\n",
    "model.encoder.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(896, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNetEncoder: 1-1                     [-1, 3, 224, 224]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 112, 112]        9,408\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 112, 112]        128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 56, 56]          --\n",
      "|    └─Sequential: 2-5                   [-1, 256, 56, 56]         --\n",
      "|    |    └─Bottleneck: 3-1              [-1, 256, 56, 56]         75,008\n",
      "|    |    └─Bottleneck: 3-2              [-1, 256, 56, 56]         70,400\n",
      "|    |    └─Bottleneck: 3-3              [-1, 256, 56, 56]         70,400\n",
      "|    └─Sequential: 2-6                   [-1, 512, 28, 28]         --\n",
      "|    |    └─Bottleneck: 3-4              [-1, 512, 28, 28]         379,392\n",
      "|    |    └─Bottleneck: 3-5              [-1, 512, 28, 28]         280,064\n",
      "|    |    └─Bottleneck: 3-6              [-1, 512, 28, 28]         280,064\n",
      "|    |    └─Bottleneck: 3-7              [-1, 512, 28, 28]         280,064\n",
      "|    └─Sequential: 2-7                   [-1, 1024, 14, 14]        --\n",
      "|    |    └─Bottleneck: 3-8              [-1, 1024, 14, 14]        1,512,448\n",
      "|    |    └─Bottleneck: 3-9              [-1, 1024, 14, 14]        1,117,184\n",
      "|    |    └─Bottleneck: 3-10             [-1, 1024, 14, 14]        1,117,184\n",
      "|    |    └─Bottleneck: 3-11             [-1, 1024, 14, 14]        1,117,184\n",
      "|    |    └─Bottleneck: 3-12             [-1, 1024, 14, 14]        1,117,184\n",
      "|    |    └─Bottleneck: 3-13             [-1, 1024, 14, 14]        1,117,184\n",
      "|    └─Sequential: 2-8                   [-1, 2048, 7, 7]          --\n",
      "|    |    └─Bottleneck: 3-14             [-1, 2048, 7, 7]          6,039,552\n",
      "|    |    └─Bottleneck: 3-15             [-1, 2048, 7, 7]          4,462,592\n",
      "|    |    └─Bottleneck: 3-16             [-1, 2048, 7, 7]          4,462,592\n",
      "├─UnetPlusPlusDecoder: 1-2               [-1, 16, 224, 224]        --\n",
      "|    └─ModuleDict: 2                     []                        --\n",
      "|    |    └─DecoderBlock: 3-17           [-1, 256, 14, 14]         7,668,736\n",
      "|    |    └─DecoderBlock: 3-18           [-1, 512, 28, 28]         9,439,232\n",
      "|    |    └─DecoderBlock: 3-19           [-1, 256, 56, 56]         2,360,320\n",
      "|    |    └─DecoderBlock: 3-20           [-1, 64, 112, 112]        221,440\n",
      "|    |    └─DecoderBlock: 3-21           [-1, 128, 28, 28]         1,622,528\n",
      "|    |    └─DecoderBlock: 3-22           [-1, 256, 56, 56]         2,950,144\n",
      "|    |    └─DecoderBlock: 3-23           [-1, 64, 112, 112]        258,304\n",
      "|    |    └─DecoderBlock: 3-24           [-1, 64, 56, 56]          553,216\n",
      "|    |    └─DecoderBlock: 3-25           [-1, 64, 112, 112]        295,168\n",
      "|    |    └─DecoderBlock: 3-26           [-1, 32, 112, 112]        101,504\n",
      "|    |    └─DecoderBlock: 3-27           [-1, 16, 224, 224]        6,976\n",
      "├─SegmentationHead: 1-3                  [-1, 2, 224, 224]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 2, 224, 224]         290\n",
      "|    └─Identity: 2-10                    [-1, 2, 224, 224]         --\n",
      "|    └─Activation: 2-11                  [-1, 2, 224, 224]         --\n",
      "|    |    └─Softmax: 3-28                [-1, 2, 224, 224]         --\n",
      "==========================================================================================\n",
      "Total params: 48,985,890\n",
      "Trainable params: 48,985,890\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.89\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 147.38\n",
      "Params size (MB): 186.87\n",
      "Estimated Total Size (MB): 334.82\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ResNetEncoder: 1-1                     [-1, 3, 224, 224]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 112, 112]        9,408\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 112, 112]        128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 112, 112]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 64, 56, 56]          --\n",
       "|    └─Sequential: 2-5                   [-1, 256, 56, 56]         --\n",
       "|    |    └─Bottleneck: 3-1              [-1, 256, 56, 56]         75,008\n",
       "|    |    └─Bottleneck: 3-2              [-1, 256, 56, 56]         70,400\n",
       "|    |    └─Bottleneck: 3-3              [-1, 256, 56, 56]         70,400\n",
       "|    └─Sequential: 2-6                   [-1, 512, 28, 28]         --\n",
       "|    |    └─Bottleneck: 3-4              [-1, 512, 28, 28]         379,392\n",
       "|    |    └─Bottleneck: 3-5              [-1, 512, 28, 28]         280,064\n",
       "|    |    └─Bottleneck: 3-6              [-1, 512, 28, 28]         280,064\n",
       "|    |    └─Bottleneck: 3-7              [-1, 512, 28, 28]         280,064\n",
       "|    └─Sequential: 2-7                   [-1, 1024, 14, 14]        --\n",
       "|    |    └─Bottleneck: 3-8              [-1, 1024, 14, 14]        1,512,448\n",
       "|    |    └─Bottleneck: 3-9              [-1, 1024, 14, 14]        1,117,184\n",
       "|    |    └─Bottleneck: 3-10             [-1, 1024, 14, 14]        1,117,184\n",
       "|    |    └─Bottleneck: 3-11             [-1, 1024, 14, 14]        1,117,184\n",
       "|    |    └─Bottleneck: 3-12             [-1, 1024, 14, 14]        1,117,184\n",
       "|    |    └─Bottleneck: 3-13             [-1, 1024, 14, 14]        1,117,184\n",
       "|    └─Sequential: 2-8                   [-1, 2048, 7, 7]          --\n",
       "|    |    └─Bottleneck: 3-14             [-1, 2048, 7, 7]          6,039,552\n",
       "|    |    └─Bottleneck: 3-15             [-1, 2048, 7, 7]          4,462,592\n",
       "|    |    └─Bottleneck: 3-16             [-1, 2048, 7, 7]          4,462,592\n",
       "├─UnetPlusPlusDecoder: 1-2               [-1, 16, 224, 224]        --\n",
       "|    └─ModuleDict: 2                     []                        --\n",
       "|    |    └─DecoderBlock: 3-17           [-1, 256, 14, 14]         7,668,736\n",
       "|    |    └─DecoderBlock: 3-18           [-1, 512, 28, 28]         9,439,232\n",
       "|    |    └─DecoderBlock: 3-19           [-1, 256, 56, 56]         2,360,320\n",
       "|    |    └─DecoderBlock: 3-20           [-1, 64, 112, 112]        221,440\n",
       "|    |    └─DecoderBlock: 3-21           [-1, 128, 28, 28]         1,622,528\n",
       "|    |    └─DecoderBlock: 3-22           [-1, 256, 56, 56]         2,950,144\n",
       "|    |    └─DecoderBlock: 3-23           [-1, 64, 112, 112]        258,304\n",
       "|    |    └─DecoderBlock: 3-24           [-1, 64, 56, 56]          553,216\n",
       "|    |    └─DecoderBlock: 3-25           [-1, 64, 112, 112]        295,168\n",
       "|    |    └─DecoderBlock: 3-26           [-1, 32, 112, 112]        101,504\n",
       "|    |    └─DecoderBlock: 3-27           [-1, 16, 224, 224]        6,976\n",
       "├─SegmentationHead: 1-3                  [-1, 2, 224, 224]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 2, 224, 224]         290\n",
       "|    └─Identity: 2-10                    [-1, 2, 224, 224]         --\n",
       "|    └─Activation: 2-11                  [-1, 2, 224, 224]         --\n",
       "|    |    └─Softmax: 3-28                [-1, 2, 224, 224]         --\n",
       "==========================================================================================\n",
       "Total params: 48,985,890\n",
       "Trainable params: 48,985,890\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.89\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 147.38\n",
       "Params size (MB): 186.87\n",
       "Estimated Total Size (MB): 334.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "import torch.functional as F\n",
    "import timm\n",
    "from torchvision.models import ResNet50_Weights, resnet50, efficientnet_b5, EfficientNet_B5_Weights\n",
    "from torchsummary import summary\n",
    "resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "efficientnet = efficientnet_b5(weights=EfficientNet_B5_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "model = smp.Linknet(\n",
    "    encoder_name=\"efficientnet-b5\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3, \n",
    "    classes=2,\n",
    "    activation = \"softmax2d\",\n",
    "    # decoder_attention_type = \"scse\"\n",
    "    \n",
    ")\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "preprocess_input = get_preprocessing_fn('resnet50', pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetEncoder(nn.Module):\n",
    "    def __init__(self, in_dim, num_class, segment_model_encoder):\n",
    "        super(EfficientNetEncoder, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.num_class = num_class\n",
    "        self.segment_model_encoder = segment_model_encoder\n",
    "        self.avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    def forward(self, x):\n",
    "        x = self.segment_model_encoder(x)\n",
    "        x = self.avg_pooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet = EfficientNetEncoder(in_dim = cfg.DATA.DIM_SIZE, num_class=cfg.DATA.NUM_CLASS, segment_model_encoder=model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.load_state_dict(efficientnet.segment_model_encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = glob.glob(\"data/brats/brats_npz/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(a[0])[\"flair\"]\n",
    "y = np.load(a[1])[\"flair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x.transpose(-1,0,1), axis=0)\n",
    "y = np.expand_dims(y.transpose(-1,0,1), axis=0)\n",
    "z = np.concatenate([x,y], axis=0)\n",
    "images = torch.from_numpy(z).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = PCL_Resnet50(\n",
    "    model,\n",
    "    image_size = 224,\n",
    "    hidden_layer_pixel = 'layer4',  # leads to output of 8x8 feature map for pixel-level learning\n",
    "    hidden_layer_instance = -2,     # leads to output for instance-level learning\n",
    "    projection_size = 256,          # size of projection output, 256 was used in the paper\n",
    "    projection_hidden_size = 2048,  # size of projection hidden dimension, paper used 2048\n",
    "    moving_average_decay = 0.99,    # exponential moving average decay of target encoder\n",
    "    ppm_num_layers = 1,             # number of layers for transform function in the pixel propagation module, 1 was optimal\n",
    "    ppm_gamma = 2,                  # sharpness of the similarity in the pixel propagation module, already at optimal value of 2\n",
    "    distance_thres = 0.7,           # ideal value is 0.7, as indicated in the paper, which makes the assumption of each feature map's pixel diagonal distance to be 1 (still unclear)\n",
    "    similarity_temperature = 0.3,   # temperature for the cosine similarity for the pixel contrastive loss\n",
    "    alpha = 1.,                      # weight of the pixel propagation loss (pixpro) vs pixel CL loss\n",
    "    use_pixpro = True,               # do pixel pro instead of pixel contrast loss, defaults to pixpro, since it is the best one\n",
    "    cutout_ratio_range = (0.6, 0.8)  # a random ratio is selected from this range for the random cutout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner = PCL_ConvNext(\n",
    "#     model,\n",
    "#     image_size = 224,\n",
    "#     hidden_layer_pixel = 'stages',  # leads to output of 8x8 feature map for pixel-level learning\n",
    "#     hidden_layer_instance = \"final_layer\",     # leads to output for instance-level learning\n",
    "#     projection_size = 256,          # size of projection output, 256 was used in the paper\n",
    "#     projection_hidden_size = 2048,  # size of projection hidden dimension, paper used 2048\n",
    "#     moving_average_decay = 0.99,    # exponential moving average decay of target encoder\n",
    "#     ppm_num_layers = 1,             # number of layers for transform function in the pixel propagation module, 1 was optimal\n",
    "#     ppm_gamma = 2,                  # sharpness of the similarity in the pixel propagation module, already at optimal value of 2\n",
    "#     distance_thres = 0.7,           # ideal value is 0.7, as indicated in the paper, which makes the assumption of each feature map's pixel diagonal distance to be 1 (still unclear)\n",
    "#     similarity_temperature = 0.3,   # temperature for the cosine similarity for the pixel contrastive loss\n",
    "#     alpha = 1.,                      # weight of the pixel propagation loss (pixpro) vs pixel CL loss\n",
    "#     use_pixpro = True,               # do pixel pro instead of pixel contrast loss, defaults to pixpro, since it is the best one\n",
    "#     cutout_ratio_range = (0.6, 0.8)  # a random ratio is selected from this range for the random cutout\n",
    "# ).cuda()\n",
    "learner = learner.cuda()\n",
    "opt = torch.optim.Adam(learner.parameters(), lr=1e-4)\n",
    "\n",
    "def sample_batch_images():\n",
    "    return torch.randn(10, 3, 224, 224)\n",
    "\n",
    "images = sample_batch_images().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100000)):\n",
    "    loss = learner(images) # if positive pixel pairs is equal to zero, the loss is equal to the instance level loss\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    if i % 100 == 0:\n",
    "        print(loss.item())\n",
    "    opt.step()\n",
    "    learner.update_moving_average() # update moving average of target encoder\n",
    "\n",
    "# after much training, save the improved model for testing on downstream task\n",
    "# torch.save(resnet, 'improved-resnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5ad64ac31307a54ea4f15d2b933f67c49aa406818b6ca8538d6cddd7352d117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
